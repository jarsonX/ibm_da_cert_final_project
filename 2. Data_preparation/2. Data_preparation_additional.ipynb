{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IT trends analysis | Dashboard creation | Additional Data Cleaning**\n",
    "**Data source:** 02_survey_data_cleaned_final.csv\n",
    "\n",
    "**Scenario:** Respondents' answers related to technologies worked with and desired to learn are all contained in a single cell per the respondent. In order to perform analysis, the information needs to be split.\n",
    "\n",
    "*Note:* In the original IBM Capstone Project this problem was entirely skipped, i.e. the data needed for the dashboard was already cleaned and ready to use. It's a shame because Pandas have a really neat function to tackle such situations - explode.\n",
    "\n",
    "**Output:** Separate tables for: LangaugeWorkedWith, LanguageDesireNextYear, DatabaseWorkedWith, DatabaseDesireNextYear. These will be imported to Power BI and mapped to the main dataset by Respondent ID.\n",
    "\n",
    "**Skills demonstrated:**\n",
    "\n",
    "* Python (Pandas)\n",
    "* Data pre-processing\n",
    "* Clean coding\n",
    "\n",
    "**Performed by:** Jarek Krzysztofik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\krzys\\Desktop\\Python\\IBM DA Capstone Project_Portfolio version\\2. Data_preparation\\survey_data_cleaned_ver2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform & Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to have copies of the original df, so any warnings regarding 'copy of a slice from df' can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. LanguageWorkedWith (LWW)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_9552\\2769744460.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  LWW_df['LanguageWorkedWith'] = LWW_df['LanguageWorkedWith'].str.replace(';',',')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Respondent LanguageWorkedWith\n",
      "0           4                  C\n",
      "0           4                C++\n",
      "0           4                 C#\n",
      "0           4             Python\n",
      "0           4                SQL\n"
     ]
    }
   ],
   "source": [
    "LWW_df = df[['Respondent', 'LanguageWorkedWith']]\n",
    "\n",
    "LWW_df['LanguageWorkedWith'] = LWW_df['LanguageWorkedWith'].str.replace(';',',')\n",
    "LWW_df = LWW_df.assign(LanguageWorkedWith=LWW_df['LanguageWorkedWith'].str.split(',')).explode('LanguageWorkedWith')\n",
    "\n",
    "print(LWW_df.head())  #for checking the result\n",
    "\n",
    "LWW_df.to_csv(r'C:\\Users\\krzys\\Desktop\\Python\\IBM DA Capstone Project_Portfolio version\\2. Data_preparation\\table_LanguageWorkedWith.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. LanguageDesireNextYear (LDNY)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Respondent LanguageDesireNextYear\n",
      "0           4                      C\n",
      "0           4                     C#\n",
      "0           4             JavaScript\n",
      "0           4                    SQL\n",
      "1           9  Bash/Shell/PowerShell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_9552\\504570447.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  LDNY_df['LanguageDesireNextYear'] = LDNY_df['LanguageDesireNextYear'].str.replace(';',',')\n"
     ]
    }
   ],
   "source": [
    "LDNY_df = df[['Respondent', 'LanguageDesireNextYear']]\n",
    "\n",
    "LDNY_df['LanguageDesireNextYear'] = LDNY_df['LanguageDesireNextYear'].str.replace(';',',')\n",
    "LDNY_df = LDNY_df.assign(LanguageDesireNextYear=LDNY_df['LanguageDesireNextYear'].str.split(',')).explode('LanguageDesireNextYear')\n",
    "\n",
    "print(LDNY_df.head())  #for checking the result\n",
    "\n",
    "LDNY_df.to_csv(r'C:\\Users\\krzys\\Desktop\\Python\\IBM DA Capstone Project_Portfolio version\\2. Data_preparation\\table_LanguageDesireNextYear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3. DatabaseWorkedWith (DWW)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Respondent DatabaseWorkedWith\n",
      "0           4              MySQL\n",
      "0           4             SQLite\n",
      "1           9           DynamoDB\n",
      "1           9         PostgreSQL\n",
      "1           9             SQLite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_9552\\1011163127.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DWW_df['DatabaseWorkedWith'] = DWW_df['DatabaseWorkedWith'].str.replace(';',',')\n"
     ]
    }
   ],
   "source": [
    "DWW_df = df[['Respondent', 'DatabaseWorkedWith']]\n",
    "\n",
    "DWW_df['DatabaseWorkedWith'] = DWW_df['DatabaseWorkedWith'].str.replace(';',',')\n",
    "DWW_df = DWW_df.assign(DatabaseWorkedWith=DWW_df['DatabaseWorkedWith'].str.split(',')).explode('DatabaseWorkedWith')\n",
    "\n",
    "print(DWW_df.head())  #for checking the result\n",
    "\n",
    "DWW_df.to_csv(r'C:\\Users\\krzys\\Desktop\\Python\\IBM DA Capstone Project_Portfolio version\\2. Data_preparation\\table_DatabaseWorkedWith.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4. DatabaseDesireNextYear (DDNY)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Respondent DatabaseDesireNextYear\n",
      "0           4                  MySQL\n",
      "0           4                 SQLite\n",
      "1           9             PostgreSQL\n",
      "1           9                  Redis\n",
      "1           9                 SQLite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_9552\\1736080348.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DDNY_df['DatabaseDesireNextYear'] = DDNY_df['DatabaseDesireNextYear'].str.replace(';',',')\n"
     ]
    }
   ],
   "source": [
    "DDNY_df = df[['Respondent', 'DatabaseDesireNextYear']]\n",
    "\n",
    "DDNY_df['DatabaseDesireNextYear'] = DDNY_df['DatabaseDesireNextYear'].str.replace(';',',')\n",
    "DDNY_df = DDNY_df.assign(DatabaseDesireNextYear=DDNY_df['DatabaseDesireNextYear'].str.split(',')).explode('DatabaseDesireNextYear')\n",
    "\n",
    "print(DDNY_df.head())  #for checking the result\n",
    "\n",
    "DDNY_df.to_csv(r'C:\\Users\\krzys\\Desktop\\Python\\IBM DA Capstone Project_Portfolio version\\2. Data_preparation\\table_DatabaseDesireNextYear.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16ee1db4c058d5c272f4c883d201aeaa1339736584614d18f3fd0d81abffbc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
